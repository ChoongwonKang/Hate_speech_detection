{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking top 10 words of each dataset by TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "\n",
    "os.chdir(r'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMSB TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(247.70676603168087, 'man'),\n",
       " (246.46270631399614, 'woman'),\n",
       " (225.22567043159842, 'people'),\n",
       " (133.46188619124007, 'sexist'),\n",
       " (105.57341954236507, 'girl'),\n",
       " (104.63247660496128, 'hate'),\n",
       " (102.347307276787, 'shit'),\n",
       " (97.15804242589361, 'work'),\n",
       " (89.82687393441205, 'female'),\n",
       " (85.78277481822326, 'fuck')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cmsb_input.csv') # import data\n",
    "\n",
    "custom_stop_words = ['sports','en','way','men','women','girls','need','good','oh','mkr', 'don', 'ha','ve','kat','want',\n",
    "                     'know','just','like','andre','lo','wa','ner','really','make',\n",
    "                     'going','think','right','time','better','look','football'] #remove non-English & stopwords\n",
    "default_stop_words = set(TfidfVectorizer(stop_words='english').get_stop_words())\n",
    "combined_stop_words = list(default_stop_words.union(custom_stop_words))\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=combined_stop_words, max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['prepro'])\n",
    "feature_array = vectorizer.get_feature_names_out()\n",
    "tfidf_sorting = tfidf_matrix.sum(axis=0).A.flatten()\n",
    "\n",
    "top_n = 10\n",
    "sorted_items = sorted(zip(tfidf_sorting, feature_array), reverse=True)[:top_n]\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SM TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(276.911330931663, 'white'),\n",
       " (182.04055215381644, 'people'),\n",
       " (123.94169949058865, 'black'),\n",
       " (77.87656881316387, 'race'),\n",
       " (75.80686009817212, 'kids'),\n",
       " (72.24151345874068, 'hope'),\n",
       " (67.11286966551256, 'thread'),\n",
       " (51.334493669320345, 'jews'),\n",
       " (50.929893418493656, 'children'),\n",
       " (47.58735624645415, 'man')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('supremacist_input.csv')\n",
    "\n",
    "custom_stop_words = ['saw','area','thank','ll','li','youtube','make','need','look','got','old','time','school','en','did','way',\n",
    "                     'say','nt','like', 'just','good','know','want','ha','wa','ner','im','ry','think','new','day','going','years','great',\n",
    "                     'io','year','ery','video','coury','whites','blacks','home','world','thing','does','maybe','er','right','looking',\n",
    "                     'let','ca','watch','said','news','post','ago','long','come','times','seen','yes','really','little'] #remove non-English & stopwords\n",
    "default_stop_words = set(TfidfVectorizer(stop_words='english').get_stop_words())\n",
    "combined_stop_words = list(default_stop_words.union(custom_stop_words))\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=combined_stop_words, max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df2['prepro'])\n",
    "feature_array = vectorizer.get_feature_names_out()\n",
    "tfidf_sorting = tfidf_matrix.sum(axis=0).A.flatten()\n",
    "\n",
    "top_n = 10\n",
    "sorted_items = sorted(zip(tfidf_sorting, feature_array), reverse=True)[:top_n]\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAC TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(147.55652516885982, 'movie'),\n",
       " (103.31849472958109, 'review'),\n",
       " (98.42659136286072, 'video'),\n",
       " (74.06823535550538, 'people'),\n",
       " (73.36721477200646, 'sir'),\n",
       " (64.13674722235349, 'india'),\n",
       " (49.99240087412689, 'bollywood'),\n",
       " (49.7807585078537, 'man'),\n",
       " (40.086748150438744, 'true'),\n",
       " (39.46001219084956, 'film')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('TRAC_input.csv')\n",
    "\n",
    "custom_stop_words = ['like', 'just','kabir','singh','good','know',\n",
    "                     'want','bhai','lo','ha','ry','right','bro','watch','agree','movies',\n",
    "                     'nice','really','great','best','youtube','roy','think','com','www'] #remove non-English & stopwords\n",
    "default_stop_words = set(TfidfVectorizer(stop_words='english').get_stop_words())\n",
    "combined_stop_words = list(default_stop_words.union(custom_stop_words))\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=combined_stop_words, max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df3['prepro'])\n",
    "feature_array = vectorizer.get_feature_names_out()\n",
    "tfidf_sorting = tfidf_matrix.sum(axis=0).A.flatten()\n",
    "\n",
    "top_n = 10\n",
    "sorted_items = sorted(zip(tfidf_sorting, feature_array), reverse=True)[:top_n]\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSOL TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1807.5605399742553, 'bitch'),\n",
       " (644.6584876026697, 'pussy'),\n",
       " (630.4868675544802, 'hoe'),\n",
       " (457.78449449406384, 'ass'),\n",
       " (457.123966574544, 'fuck'),\n",
       " (411.2587828142525, 'trash'),\n",
       " (399.3763762060491, 'shit'),\n",
       " (381.98449776784094, 'nigga'),\n",
       " (281.6739648947166, 'love'),\n",
       " (236.47528157964675, 'bad')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('Davidson2017.csv')\n",
    "\n",
    "custom_stop_words = ['yall','like','ai','im','know','got','amp','ca','bitches','hoes','just','lol','niggas'] #remove non-English & stopwords\n",
    "default_stop_words = set(TfidfVectorizer(stop_words='english').get_stop_words())\n",
    "combined_stop_words = list(default_stop_words.union(custom_stop_words))\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=combined_stop_words, max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df4['prepro'])\n",
    "feature_array = vectorizer.get_feature_names_out()\n",
    "tfidf_sorting = tfidf_matrix.sum(axis=0).A.flatten()\n",
    "\n",
    "top_n = 10\n",
    "sorted_items = sorted(zip(tfidf_sorting, feature_array), reverse=True)[:top_n]\n",
    "sorted_items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
